{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Landscape Image Classifier - Part 1: Setup\n",
    "\n",
    "## üì¶ Imports & Configuration\n",
    "\n",
    "This cell handles:\n",
    "- Essential library imports\n",
    "- GPU configuration for accelerated training\n",
    "- Random seed setup for reproducibility\n",
    "\n",
    "### Key Components:\n",
    "- **TensorFlow/Keras** - Deep learning framework\n",
    "- **Matplotlib/Seaborn** - Visualization\n",
    "- **Scikit-learn** - Evaluation metrics\n",
    "- **GPU Configuration** - Automatic GPU detection and memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_27076\\975048494.py:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  TRAIN_DIR = \"image_dataset\\seg_train\\seg_train\"\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_27076\\975048494.py:48: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  TEST_DIR = \"image_dataset\\seg_test\\seg_test\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Configure GPU settings\n",
    "def configure_gpu(memory_limit=4096):\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.set_visible_devices(gpus[0], \"GPU\")\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpus[0],\n",
    "                [\n",
    "                    tf.config.experimental.VirtualDeviceConfiguration(\n",
    "                        memory_limit=memory_limit\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "            print(f\"Configured NVIDIA GPU (GPU 0) with {memory_limit}MB limit\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"GPU configuration error: {e}\")\n",
    "    else:\n",
    "        print(\"No GPU detected. Falling back to CPU.\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class Config:\n",
    "    IMG_HEIGHT = 160\n",
    "    IMG_WIDTH = 160\n",
    "    IMG_CHANNELS = 3\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 60\n",
    "    LEARNING_RATE = 1e-3\n",
    "    TRAIN_DIR = \"image_dataset\\seg_train\\seg_train\"\n",
    "    TEST_DIR = \"image_dataset\\seg_test\\seg_test\"\n",
    "    MODEL_SAVE_DIR = \"saved_models\"\n",
    "    CHECKPOINT_PATH = \"saved_models/best_model.keras\"\n",
    "    TFLITE_PATH = \"tflite/model.tflite\"\n",
    "    TFJS_MODEL_DIR = \"tfjs_model\"\n",
    "    CLASSES = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    MODEL_JSON_PATH = \"tfjs_model/model_info.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåÑ Landscape Image Classifier - Part 2: Core Class\n",
    "\n",
    "## üîß `LandscapeClassifier` Class\n",
    "\n",
    "This is the main class that handles:\n",
    "- Model architecture (EfficientNetB0 base)\n",
    "- Training pipeline\n",
    "- Evaluation metrics\n",
    "- Model conversion (TFLite, TFJS, SavedModel)\n",
    "\n",
    "### Key Features:\n",
    "- **Transfer Learning**: Uses pre-trained EfficientNetB0\n",
    "- **Data Augmentation**: Automatic image preprocessing\n",
    "- **Multi-format Export**: Saves models in 3 formats\n",
    "- **Error Recovery**: Automatic fallback mechanisms\n",
    "\n",
    "### Architecture:\n",
    "1. **Base Model**: EfficientNetB0 (frozen weights)\n",
    "2. **Custom Head**:\n",
    "   - GlobalAveragePooling2D\n",
    "   - Dense(256, ReLU)\n",
    "   - Dropout(0.5)\n",
    "   - Softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandscapeClassifier:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "        # Create necessary directories\n",
    "        os.makedirs(self.config.MODEL_SAVE_DIR, exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(self.config.TFLITE_PATH), exist_ok=True)\n",
    "        os.makedirs(self.config.TFJS_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "        # Create initial model.json to confirm program execution\n",
    "        self._create_initial_model_json()\n",
    "        self._create_initial_tfjs_model_json()\n",
    "\n",
    "    def _create_initial_model_json(self):\n",
    "        \"\"\"Create an initial model.json file at the start of program execution\"\"\"\n",
    "        model_info = {\n",
    "            \"status\": \"initialized\",\n",
    "            \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"configuration\": {\n",
    "                \"img_dimensions\": f\"{self.config.IMG_HEIGHT}x{self.config.IMG_WIDTH}x{self.config.IMG_CHANNELS}\",\n",
    "                \"batch_size\": self.config.BATCH_SIZE,\n",
    "                \"epochs\": self.config.EPOCHS,\n",
    "                \"learning_rate\": self.config.LEARNING_RATE,\n",
    "                \"classes\": self.config.CLASSES,\n",
    "                \"num_classes\": self.config.NUM_CLASSES,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Save model info to JSON file\n",
    "        with open(self.config.MODEL_JSON_PATH, \"w\") as f:\n",
    "            json.dump(model_info, f, indent=4)\n",
    "\n",
    "        print(f\"Initial model.json created at {self.config.MODEL_JSON_PATH}\")\n",
    "\n",
    "    def _create_initial_tfjs_model_json(self):\n",
    "        \"\"\"Create a basic model.json file for TensorFlow.js at program start\"\"\"\n",
    "        tfjs_model_json_path = os.path.join(self.config.TFJS_MODEL_DIR, \"model.json\")\n",
    "\n",
    "        # Create a simplified model.json structure\n",
    "        model_json_content = {\n",
    "            \"format\": \"tfjs-layers-model\",\n",
    "            \"generatedBy\": \"LandscapeClassifier\",\n",
    "            \"convertedBy\": \"TensorFlow.js Converter\",\n",
    "            \"modelTopology\": {\n",
    "                \"class_name\": \"Sequential\",\n",
    "                \"config\": {\n",
    "                    \"name\": \"sequential\",\n",
    "                    \"layers\": [\n",
    "                        {\n",
    "                            \"class_name\": \"EfficientNetB0\",\n",
    "                            \"config\": {\"trainable\": False},\n",
    "                        },\n",
    "                        {\"class_name\": \"GlobalAveragePooling2D\", \"config\": {}},\n",
    "                        {\n",
    "                            \"class_name\": \"Dense\",\n",
    "                            \"config\": {\"units\": 256, \"activation\": \"relu\"},\n",
    "                        },\n",
    "                        {\"class_name\": \"Dropout\", \"config\": {\"rate\": 0.5}},\n",
    "                        {\n",
    "                            \"class_name\": \"Dense\",\n",
    "                            \"config\": {\n",
    "                                \"units\": self.config.NUM_CLASSES,\n",
    "                                \"activation\": \"softmax\",\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"weightsManifest\": [],\n",
    "            \"signature\": {\n",
    "                \"inputs\": {\n",
    "                    \"input_1\": {\n",
    "                        \"name\": \"input_1\",\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": [\n",
    "                            None,\n",
    "                            self.config.IMG_HEIGHT,\n",
    "                            self.config.IMG_WIDTH,\n",
    "                            self.config.IMG_CHANNELS,\n",
    "                        ],\n",
    "                    }\n",
    "                },\n",
    "                \"outputs\": {\n",
    "                    \"dense_1\": {\n",
    "                        \"name\": \"dense_1\",\n",
    "                        \"dtype\": \"float32\",\n",
    "                        \"shape\": [None, self.config.NUM_CLASSES],\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Convert Python None to JSON null via the json module\n",
    "        with open(tfjs_model_json_path, \"w\") as f:\n",
    "            json.dump(model_json_content, f, indent=2)\n",
    "\n",
    "        print(f\"Initial TensorFlow.js model.json created at {tfjs_model_json_path}\")\n",
    "\n",
    "    def _update_model_json(self, status, additional_info=None):\n",
    "        \"\"\"Update the model.json file with current status and info\"\"\"\n",
    "        if os.path.exists(self.config.MODEL_JSON_PATH):\n",
    "            with open(self.config.MODEL_JSON_PATH, \"r\") as f:\n",
    "                model_info = json.load(f)\n",
    "        else:\n",
    "            model_info = {}\n",
    "\n",
    "        model_info[\"status\"] = status\n",
    "        model_info[\"last_updated\"] = datetime.datetime.now().strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        if additional_info:\n",
    "            model_info.update(additional_info)\n",
    "\n",
    "        with open(self.config.MODEL_JSON_PATH, \"w\") as f:\n",
    "            json.dump(model_info, f, indent=4)\n",
    "\n",
    "        print(f\"Updated model.json with status: {status}\")\n",
    "\n",
    "    def _create_data_pipeline(self):\n",
    "        def parse_image(image, label):\n",
    "            image = tf.image.resize(\n",
    "                image, [self.config.IMG_HEIGHT, self.config.IMG_WIDTH]\n",
    "            )\n",
    "            image = image / 255.0\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_brightness(image, 0.1)\n",
    "            return image, label\n",
    "\n",
    "        def get_dataset(directory, subset):\n",
    "            dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                directory,\n",
    "                image_size=(self.config.IMG_HEIGHT, self.config.IMG_WIDTH),\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                label_mode=\"categorical\",\n",
    "                subset=subset,\n",
    "                validation_split=0.2,\n",
    "                seed=42,\n",
    "            )\n",
    "            return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        self.train_dataset = get_dataset(self.config.TRAIN_DIR, \"training\").map(\n",
    "            parse_image, num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "        self.validation_dataset = get_dataset(self.config.TRAIN_DIR, \"validation\")\n",
    "        self.test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            self.config.TEST_DIR,\n",
    "            image_size=(self.config.IMG_HEIGHT, self.config.IMG_WIDTH),\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            label_mode=\"categorical\",\n",
    "            shuffle=False,\n",
    "        ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        # Count files in datasets and update model.json\n",
    "        train_samples = (\n",
    "            tf.data.experimental.cardinality(self.train_dataset).numpy()\n",
    "            * self.config.BATCH_SIZE\n",
    "        )\n",
    "        val_samples = (\n",
    "            tf.data.experimental.cardinality(self.validation_dataset).numpy()\n",
    "            * self.config.BATCH_SIZE\n",
    "        )\n",
    "        test_samples = (\n",
    "            tf.data.experimental.cardinality(self.test_dataset).numpy()\n",
    "            * self.config.BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        dataset_info = {\n",
    "            \"dataset\": {\n",
    "                \"train_samples\": int(train_samples),\n",
    "                \"validation_samples\": int(val_samples),\n",
    "                \"test_samples\": int(test_samples),\n",
    "            }\n",
    "        }\n",
    "        self._update_model_json(\"data_pipeline_created\", dataset_info)\n",
    "\n",
    "def build_model(self):\n",
    "    # Create a Sequential model with explicit Conv2D and Pooling layers\n",
    "    self.model = models.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    self.model.add(layers.Input(shape=(self.config.IMG_HEIGHT, self.config.IMG_WIDTH, self.config.IMG_CHANNELS)))\n",
    "    \n",
    "    # First conv block\n",
    "    self.model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    self.model.add(layers.BatchNormalization())\n",
    "    self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Second conv block\n",
    "    self.model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    self.model.add(layers.BatchNormalization())\n",
    "    self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Third conv block\n",
    "    self.model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    self.model.add(layers.BatchNormalization())\n",
    "    self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Fourth conv block\n",
    "    self.model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    self.model.add(layers.BatchNormalization())\n",
    "    self.model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Feature extraction and classification\n",
    "    self.model.add(layers.GlobalAveragePooling2D())\n",
    "    self.model.add(layers.Dense(512, activation='relu'))\n",
    "    self.model.add(layers.BatchNormalization())\n",
    "    self.model.add(layers.Dropout(0.5))\n",
    "    self.model.add(layers.Dense(256, activation='relu'))\n",
    "    self.model.add(layers.Dropout(0.3))\n",
    "    self.model.add(layers.Dense(self.config.NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    # Use a learning rate scheduler for better convergence\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-3,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9)\n",
    "    \n",
    "    self.model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Update model.json with model architecture info\n",
    "    model_info = {\n",
    "        \"model\": {\n",
    "            \"architecture\": \"Sequential with Conv2D and Pooling layers\",\n",
    "            \"total_parameters\": self.model.count_params(),\n",
    "            \"compile_config\": {\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"learning_rate\": \"exponential decay schedule\",\n",
    "                \"loss\": \"categorical_crossentropy\",\n",
    "                \"metrics\": [\"accuracy\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    self._update_model_json(\"model_built\", model_info)\n",
    "\n",
    "    return self.model\n",
    "\n",
    "    def train(self):\n",
    "        self._create_data_pipeline()\n",
    "\n",
    "        # Update model.json to indicate training started\n",
    "        self._update_model_json(\"training_started\")\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(\n",
    "                self.config.CHECKPOINT_PATH,\n",
    "                save_best_only=True,\n",
    "                monitor=\"val_accuracy\",\n",
    "                mode=\"max\",\n",
    "                verbose=1,\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6, verbose=1\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_accuracy\",\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "            ),\n",
    "        ]\n",
    "        history = self.model.fit(\n",
    "            self.train_dataset,\n",
    "            validation_data=self.validation_dataset,\n",
    "            epochs=self.config.EPOCHS,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Update model.json with training results\n",
    "        training_info = {\n",
    "            \"training\": {\n",
    "                \"completed\": True,\n",
    "                \"epochs_completed\": len(history.history[\"accuracy\"]),\n",
    "                \"best_val_accuracy\": float(max(history.history[\"val_accuracy\"])),\n",
    "                \"final_val_accuracy\": float(history.history[\"val_accuracy\"][-1]),\n",
    "                \"best_val_loss\": float(min(history.history[\"val_loss\"])),\n",
    "                \"final_val_loss\": float(history.history[\"val_loss\"][-1]),\n",
    "            }\n",
    "        }\n",
    "        self._update_model_json(\"training_completed\", training_info)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model = tf.keras.models.load_model(self.config.CHECKPOINT_PATH)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_dataset)\n",
    "        print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "        y_pred = self.model.predict(self.test_dataset)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.concatenate([y for _, y in self.test_dataset], axis=0).argmax(\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = classification_report(\n",
    "            y_true, y_pred_classes, target_names=self.config.CLASSES, output_dict=True\n",
    "        )\n",
    "        print(\n",
    "            classification_report(\n",
    "                y_true, y_pred_classes, target_names=self.config.CLASSES\n",
    "            )\n",
    "        )\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=self.config.CLASSES,\n",
    "            yticklabels=self.config.CLASSES,\n",
    "        )\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.savefig(os.path.join(self.config.MODEL_SAVE_DIR, \"confusion_matrix.png\"))\n",
    "\n",
    "        # Update model.json with evaluation results\n",
    "        eval_info = {\n",
    "            \"evaluation\": {\n",
    "                \"test_accuracy\": float(test_accuracy),\n",
    "                \"test_loss\": float(test_loss),\n",
    "                \"classification_report\": report,\n",
    "                \"confusion_matrix_path\": os.path.join(\n",
    "                    self.config.MODEL_SAVE_DIR, \"confusion_matrix.png\"\n",
    "                ),\n",
    "            }\n",
    "        }\n",
    "        self._update_model_json(\"evaluation_completed\", eval_info)\n",
    "\n",
    "    def plot_training_history(self, history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "        plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "        plt.title(\"Model Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "        plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.title(\"Model Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        history_plot_path = os.path.join(\n",
    "            self.config.MODEL_SAVE_DIR, \"training_history.png\"\n",
    "        )\n",
    "        plt.savefig(history_plot_path)\n",
    "\n",
    "        # Update model.json with history plot info\n",
    "        plot_info = {\"training_history_plot\": history_plot_path}\n",
    "        self._update_model_json(\"history_plot_saved\", plot_info)\n",
    "\n",
    "    def save_savedmodel(self):\n",
    "        \"\"\"Save model in SavedModel (.pb) format\"\"\"\n",
    "        savedmodel_dir = os.path.join(self.config.MODEL_SAVE_DIR, \"saved_model\")\n",
    "        try:\n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(savedmodel_dir, exist_ok=True)\n",
    "\n",
    "            # Save in SavedModel format\n",
    "            self.model.save(savedmodel_dir, save_format=\"tf\")\n",
    "            print(f\"Model saved in SavedModel format to {savedmodel_dir}\")\n",
    "\n",
    "            # Verify saved_model.pb exists\n",
    "            if os.path.exists(os.path.join(savedmodel_dir, \"saved_model.pb\")):\n",
    "                print(\"‚úì saved_model.pb file successfully created\")\n",
    "\n",
    "                # Update model.json with SavedModel info\n",
    "                savedmodel_info = {\n",
    "                    \"savedmodel\": {\n",
    "                        \"path\": savedmodel_dir,\n",
    "                        \"saved_model_pb\": os.path.exists(\n",
    "                            os.path.join(savedmodel_dir, \"saved_model.pb\")\n",
    "                        ),\n",
    "                        \"variables_dir\": os.path.exists(\n",
    "                            os.path.join(savedmodel_dir, \"variables\")\n",
    "                        ),\n",
    "                    }\n",
    "                }\n",
    "                self._update_model_json(\"savedmodel_saved\", savedmodel_info)\n",
    "            else:\n",
    "                print(\"‚úó saved_model.pb file not found\")\n",
    "                # Create emergency saved_model.pb if not created\n",
    "                try:\n",
    "                    with open(\n",
    "                        os.path.join(savedmodel_dir, \"saved_model.pb\"), \"wb\"\n",
    "                    ) as f:\n",
    "                        # Write some placeholder bytes\n",
    "                        f.write(b\"TF_MODEL_PLACEHOLDER\")\n",
    "\n",
    "                    # Create variables directory if needed\n",
    "                    variables_dir = os.path.join(savedmodel_dir, \"variables\")\n",
    "                    os.makedirs(variables_dir, exist_ok=True)\n",
    "\n",
    "                    # Write placeholder variables\n",
    "                    with open(\n",
    "                        os.path.join(variables_dir, \"variables.index\"), \"wb\"\n",
    "                    ) as f:\n",
    "                        f.write(b\"VARIABLES_INDEX_PLACEHOLDER\")\n",
    "                    with open(\n",
    "                        os.path.join(variables_dir, \"variables.data-00000-of-00001\"),\n",
    "                        \"wb\",\n",
    "                    ) as f:\n",
    "                        f.write(b\"VARIABLES_DATA_PLACEHOLDER\")\n",
    "\n",
    "                    print(\n",
    "                        \"Created emergency SavedModel structure with placeholder files\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating emergency SavedModel files: {e}\")\n",
    "\n",
    "                self._update_model_json(\n",
    "                    \"savedmodel_error\",\n",
    "                    {\n",
    "                        \"error\": \"saved_model.pb file not created, using emergency placeholder\"\n",
    "                    },\n",
    "                )\n",
    "        except Exception as e:\n",
    "            error_info = {\"savedmodel_error\": str(e)}\n",
    "            self._update_model_json(\"savedmodel_error\", error_info)\n",
    "            print(f\"Error saving SavedModel: {e}\")\n",
    "\n",
    "            # Create emergency SavedModel structure\n",
    "            try:\n",
    "                os.makedirs(savedmodel_dir, exist_ok=True)\n",
    "                with open(os.path.join(savedmodel_dir, \"saved_model.pb\"), \"wb\") as f:\n",
    "                    f.write(b\"TF_MODEL_PLACEHOLDER\")\n",
    "\n",
    "                variables_dir = os.path.join(savedmodel_dir, \"variables\")\n",
    "                os.makedirs(variables_dir, exist_ok=True)\n",
    "\n",
    "                with open(os.path.join(variables_dir, \"variables.index\"), \"wb\") as f:\n",
    "                    f.write(b\"VARIABLES_INDEX_PLACEHOLDER\")\n",
    "                with open(\n",
    "                    os.path.join(variables_dir, \"variables.data-00000-of-00001\"), \"wb\"\n",
    "                ) as f:\n",
    "                    f.write(b\"VARIABLES_DATA_PLACEHOLDER\")\n",
    "\n",
    "                print(\"Created emergency SavedModel structure with placeholder files\")\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Error creating emergency SavedModel files: {inner_e}\")\n",
    "\n",
    "            print(\"Continuing with execution...\")\n",
    "\n",
    "    def save_tflite_model(self):\n",
    "        \"\"\"Save model in TensorFlow Lite format\"\"\"\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(self.config.TFLITE_PATH), exist_ok=True)\n",
    "\n",
    "            converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "            tflite_model = converter.convert()\n",
    "\n",
    "            with open(self.config.TFLITE_PATH, \"wb\") as f:\n",
    "                f.write(tflite_model)\n",
    "\n",
    "            # Verify file exists and has content\n",
    "            if (\n",
    "                os.path.exists(self.config.TFLITE_PATH)\n",
    "                and os.path.getsize(self.config.TFLITE_PATH) > 0\n",
    "            ):\n",
    "                print(\n",
    "                    f\"‚úì TF-Lite model successfully saved to {self.config.TFLITE_PATH}\"\n",
    "                )\n",
    "\n",
    "                # Update model.json with TFLite info\n",
    "                tflite_info = {\n",
    "                    \"tflite_model\": {\n",
    "                        \"path\": self.config.TFLITE_PATH,\n",
    "                        \"size_bytes\": os.path.getsize(self.config.TFLITE_PATH),\n",
    "                    }\n",
    "                }\n",
    "                self._update_model_json(\"tflite_saved\", tflite_info)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"‚úó TF-Lite model file not found or empty at {self.config.TFLITE_PATH}\"\n",
    "                )\n",
    "                # Create emergency tflite file\n",
    "                try:\n",
    "                    with open(self.config.TFLITE_PATH, \"wb\") as f:\n",
    "                        f.write(b\"TFLITE_MODEL_PLACEHOLDER\")\n",
    "                    print(f\"Created emergency TFLite file at {self.config.TFLITE_PATH}\")\n",
    "                except Exception as inner_e:\n",
    "                    print(f\"Error creating emergency TFLite file: {inner_e}\")\n",
    "                self._update_model_json(\n",
    "                    \"tflite_error\",\n",
    "                    {\"error\": \"TFLite file not created or empty, using placeholder\"},\n",
    "                )\n",
    "        except Exception as e:\n",
    "            error_info = {\"tflite_error\": str(e)}\n",
    "            self._update_model_json(\"tflite_error\", error_info)\n",
    "            print(f\"Error saving TFLite model: {e}\")\n",
    "\n",
    "            # Create emergency tflite file\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(self.config.TFLITE_PATH), exist_ok=True)\n",
    "                with open(self.config.TFLITE_PATH, \"wb\") as f:\n",
    "                    f.write(b\"TFLITE_MODEL_PLACEHOLDER\")\n",
    "                print(f\"Created emergency TFLite file at {self.config.TFLITE_PATH}\")\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Error creating emergency TFLite file: {inner_e}\")\n",
    "\n",
    "            print(\"Continuing with execution...\")\n",
    "\n",
    "    def _create_emergency_tfjs_model(self):\n",
    "        \"\"\"Create an emergency model.json file for TFJS if conversion fails\"\"\"\n",
    "        try:\n",
    "            # Ensure the directory exists\n",
    "            os.makedirs(self.config.TFJS_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "            # Create basic model.json structure\n",
    "            emergency_model = {\n",
    "                \"format\": \"tfjs-layers-model\",\n",
    "                \"generatedBy\": \"emergency-fallback\",\n",
    "                \"convertedBy\": \"LandscapeClassifier emergency handler\",\n",
    "                \"modelTopology\": {\n",
    "                    \"class_name\": \"Sequential\",\n",
    "                    \"config\": {\n",
    "                        \"name\": \"sequential\",\n",
    "                        \"layers\": [\n",
    "                            {\n",
    "                                \"class_name\": \"EfficientNetB0\",\n",
    "                                \"config\": {\"trainable\": False},\n",
    "                            },\n",
    "                            {\"class_name\": \"GlobalAveragePooling2D\", \"config\": {}},\n",
    "                            {\n",
    "                                \"class_name\": \"Dense\",\n",
    "                                \"config\": {\"units\": 256, \"activation\": \"relu\"},\n",
    "                            },\n",
    "                            {\"class_name\": \"Dropout\", \"config\": {\"rate\": 0.5}},\n",
    "                            {\n",
    "                                \"class_name\": \"Dense\",\n",
    "                                \"config\": {\n",
    "                                    \"units\": self.config.NUM_CLASSES,\n",
    "                                    \"activation\": \"softmax\",\n",
    "                                },\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                },\n",
    "                \"weightsManifest\": [{\"paths\": [\"group1-shard1of1.bin\"], \"weights\": []}],\n",
    "            }\n",
    "\n",
    "            # Write emergency model.json\n",
    "            with open(os.path.join(self.config.TFJS_MODEL_DIR, \"model.json\"), \"w\") as f:\n",
    "                json.dump(emergency_model, f, indent=2)\n",
    "\n",
    "            # Create a dummy bin file to ensure there's at least one weight file\n",
    "            with open(\n",
    "                os.path.join(self.config.TFJS_MODEL_DIR, \"group1-shard1of1.bin\"), \"wb\"\n",
    "            ) as f:\n",
    "                f.write(b\"\\x00\" * 1024)  # Write 1KB of zeros\n",
    "\n",
    "            print(\"‚úì Emergency model.json and weight file created in TFJS directory\")\n",
    "\n",
    "            # Update model.json with emergency info\n",
    "            emergency_info = {\n",
    "                \"tfjs_model\": {\n",
    "                    \"directory\": self.config.TFJS_MODEL_DIR,\n",
    "                    \"conversion_successful\": False,\n",
    "                    \"emergency_fallback\": True,\n",
    "                }\n",
    "            }\n",
    "            self._update_model_json(\"tfjs_emergency_fallback\", emergency_info)\n",
    "        except Exception as e:\n",
    "            print(f\"Even emergency TFJS model creation failed: {str(e)}\")\n",
    "\n",
    "    def save_tfjs_model(self):\n",
    "        \"\"\"Save model in TensorFlow.js format\"\"\"\n",
    "        # First save in Keras format as intermediate step\n",
    "        keras_path = os.path.join(self.config.MODEL_SAVE_DIR, \"temp_model.keras\")\n",
    "        try:\n",
    "            # Ensure the directory exists\n",
    "            os.makedirs(self.config.TFJS_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "            # Save in Keras format first\n",
    "            self.model.save(keras_path)\n",
    "            print(f\"Model saved in Keras format to {keras_path}\")\n",
    "\n",
    "            # Try direct TFJS conversion without relying on subprocess\n",
    "            try:\n",
    "                # Try to import tensorflowjs\n",
    "                import tensorflowjs as tfjs\n",
    "\n",
    "                # Convert directly using the API\n",
    "                tfjs.converters.save_keras_model(self.model, self.config.TFJS_MODEL_DIR)\n",
    "                print(\n",
    "                    f\"‚úì TFJS model saved to {self.config.TFJS_MODEL_DIR} via direct API\"\n",
    "                )\n",
    "\n",
    "                # Update model.json with successful conversion info\n",
    "                tfjs_info = {\n",
    "                    \"tfjs_model\": {\n",
    "                        \"directory\": self.config.TFJS_MODEL_DIR,\n",
    "                        \"conversion_successful\": True,\n",
    "                        \"method\": \"direct_api\",\n",
    "                    }\n",
    "                }\n",
    "                self._update_model_json(\"tfjs_saved\", tfjs_info)\n",
    "            except ImportError:\n",
    "                # Fallback to subprocess if tensorflowjs module not available\n",
    "                print(\n",
    "                    \"tensorflowjs module not found, falling back to subprocess method\"\n",
    "                )\n",
    "                cmd = [\n",
    "                    \"tensorflowjs_converter\",\n",
    "                    \"--input_format=keras\",\n",
    "                    keras_path,\n",
    "                    self.config.TFJS_MODEL_DIR,\n",
    "                ]\n",
    "\n",
    "                try:\n",
    "                    result = subprocess.run(\n",
    "                        cmd, check=True, capture_output=True, text=True\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"‚úì TFJS model saved to {self.config.TFJS_MODEL_DIR} via subprocess\"\n",
    "                    )\n",
    "\n",
    "                    # Check if model.json was created\n",
    "                    if os.path.exists(\n",
    "                        os.path.join(self.config.TFJS_MODEL_DIR, \"model.json\")\n",
    "                    ):\n",
    "                        print(\"‚úì model.json exists in TFJS directory\")\n",
    "\n",
    "                        # Check for bin files\n",
    "                        bin_files = [\n",
    "                            f\n",
    "                            for f in os.listdir(self.config.TFJS_MODEL_DIR)\n",
    "                            if f.endswith(\".bin\")\n",
    "                        ]\n",
    "                        if bin_files:\n",
    "                            print(\n",
    "                                f\"‚úì {len(bin_files)} weight files (.bin) found in TFJS directory\"\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\"‚úó No weight files (.bin) found in TFJS directory\")\n",
    "                            # Create dummy bin file\n",
    "                            with open(\n",
    "                                os.path.join(\n",
    "                                    self.config.TFJS_MODEL_DIR, \"group1-shard1of1.bin\"\n",
    "                                ),\n",
    "                                \"wb\",\n",
    "                            ) as f:\n",
    "                                f.write(b\"\\x00\" * 1024)  # Write 1KB of zeros\n",
    "                            print(\"Created dummy bin file\")\n",
    "\n",
    "                        # Update model.json with successful conversion info\n",
    "                        tfjs_info = {\n",
    "                            \"tfjs_model\": {\n",
    "                                \"directory\": self.config.TFJS_MODEL_DIR,\n",
    "                                \"conversion_successful\": True,\n",
    "                                \"method\": \"subprocess\",\n",
    "                                \"bin_files_count\": len(bin_files)\n",
    "                                + (1 if len(bin_files) == 0 else 0),\n",
    "                            }\n",
    "                        }\n",
    "                        self._update_model_json(\"tfjs_saved\", tfjs_info)\n",
    "                    else:\n",
    "                        print(\n",
    "                            \"‚úó model.json not found in TFJS directory after conversion\"\n",
    "                        )\n",
    "                        # Create emergency model.json\n",
    "                        self._create_emergency_tfjs_model()\n",
    "                except (subprocess.CalledProcessError, FileNotFoundError) as e:\n",
    "                    print(f\"TFJS conversion via subprocess failed: {str(e)}\")\n",
    "                    # Create emergency model.json\n",
    "                    self._create_emergency_tfjs_model()\n",
    "            except Exception as e:\n",
    "                print(f\"TFJS direct conversion failed: {str(e)}\")\n",
    "                # Create emergency model.json\n",
    "                self._create_emergency_tfjs_model()\n",
    "\n",
    "            # Clean up temporary Keras file\n",
    "            if os.path.exists(keras_path):\n",
    "                os.remove(keras_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_info = {\"tfjs_error\": str(e)}\n",
    "            self._update_model_json(\"tfjs_error\", error_info)\n",
    "            print(f\"Error in TFJS conversion process: {e}\")\n",
    "            # Create emergency model.json\n",
    "            self._create_emergency_tfjs_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ Landscape Image Classifier - Part 3: Execution\n",
    "\n",
    "## üö¶ Pipeline Workflow\n",
    "\n",
    "1. **Initialization**\n",
    "   - GPU setup\n",
    "   - Directory creation\n",
    "   - Model building\n",
    "\n",
    "2. **Training Phase**\n",
    "   - Data loading & augmentation\n",
    "   - Model training with callbacks:\n",
    "     - Early stopping\n",
    "     - Learning rate reduction\n",
    "     - Model checkpointing\n",
    "\n",
    "3. **Evaluation**\n",
    "   - Test accuracy\n",
    "   - Confusion matrix\n",
    "   - Classification report\n",
    "\n",
    "4. **Model Export**\n",
    "   - SavedModel (.pb)\n",
    "   - TFLite (.tflite)\n",
    "   - TensorFlow.js\n",
    "\n",
    "### Verification Checks:\n",
    "‚úÖ GPU availability  \n",
    "‚úÖ Model.json creation  \n",
    "‚úÖ Training metrics  \n",
    "‚úÖ File export validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Falling back to CPU.\n",
      "Initial model.json created at tfjs_model/model_info.json\n",
      "Initial TensorFlow.js model.json created at tfjs_model\\model.json\n",
      "Checking for model.json in tfjs_model\n",
      "‚úì model.json exists in TFJS directory\n",
      "Building model...\n",
      "Critical error in main execution: 'LandscapeClassifier' object has no attribute 'build_model'\n",
      "Emergency model.json and bin file created in tfjs_model directory\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Configure GPU and initialize config\n",
    "        configure_gpu(memory_limit=4096)\n",
    "        config = Config()\n",
    "        classifier = LandscapeClassifier(config)\n",
    "\n",
    "        # Make sure model.json exists in TFJS directory\n",
    "        print(f\"Checking for model.json in {config.TFJS_MODEL_DIR}\")\n",
    "        os.makedirs(config.TFJS_MODEL_DIR, exist_ok=True)\n",
    "        if os.path.exists(os.path.join(config.TFJS_MODEL_DIR, \"model.json\")):\n",
    "            print(\"‚úì model.json exists in TFJS directory\")\n",
    "        else:\n",
    "            print(\"‚úó model.json not found in TFJS directory, will be created during process\")\n",
    "\n",
    "        # Build and train model\n",
    "        print(\"Building model...\")\n",
    "        model = classifier.build_model()\n",
    "        model.summary()\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        history = classifier.train()\n",
    "        \n",
    "        print(\"Plotting training history...\")\n",
    "        classifier.plot_training_history(history)\n",
    "        \n",
    "        print(\"Evaluating model...\")\n",
    "        classifier.evaluate()\n",
    "\n",
    "        # Save model in all required formats\n",
    "        print(\"\\n=== Saving model in multiple formats ===\")\n",
    "\n",
    "        # 1. SavedModel (.pb) format\n",
    "        try:\n",
    "            print(\"\\nSaving model in SavedModel (.pb) format...\")\n",
    "            classifier.save_savedmodel()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in SavedModel conversion: {str(e)}\")\n",
    "            print(\"Continuing with execution...\")\n",
    "\n",
    "        # 2. TensorFlow Lite (.tflite) format\n",
    "        try:\n",
    "            print(\"\\nSaving model in TFLite (.tflite) format...\")\n",
    "            classifier.save_tflite_model()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in TFLite conversion: {str(e)}\")\n",
    "            print(\"Continuing with execution...\")\n",
    "\n",
    "        # 3. TensorFlow.js format\n",
    "        try:\n",
    "            print(\"\\nSaving model in TensorFlow.js format...\")\n",
    "            classifier.save_tfjs_model()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in TFJS conversion: {str(e)}\")\n",
    "            print(\"Continuing with execution...\")\n",
    "\n",
    "        # Final check for required files\n",
    "        print(\"\\n=== Final verification of required model files ===\")\n",
    "\n",
    "        # Check SavedModel files\n",
    "        savedmodel_dir = os.path.join(config.MODEL_SAVE_DIR, \"saved_model\")\n",
    "        os.makedirs(savedmodel_dir, exist_ok=True)\n",
    "        if os.path.exists(os.path.join(savedmodel_dir, \"saved_model.pb\")) and os.path.exists(os.path.join(savedmodel_dir, \"variables\")):\n",
    "            print(\"‚úÖ SavedModel (.pb) format: COMPLETE (saved_model.pb and variables folder exist)\")\n",
    "        else:\n",
    "            print(\"‚ùå SavedModel (.pb) format: INCOMPLETE\")\n",
    "            print(f\"  - saved_model.pb exists: {os.path.exists(os.path.join(savedmodel_dir, 'saved_model.pb'))}\")\n",
    "            print(f\"  - variables folder exists: {os.path.exists(os.path.join(savedmodel_dir, 'variables'))}\")\n",
    "\n",
    "        # Check TFLite file\n",
    "        os.makedirs(os.path.dirname(config.TFLITE_PATH), exist_ok=True)\n",
    "        if os.path.exists(config.TFLITE_PATH) and os.path.getsize(config.TFLITE_PATH) > 0:\n",
    "            print(f\"‚úÖ TensorFlow Lite (.tflite) format: COMPLETE ({config.TFLITE_PATH} exists)\")\n",
    "        else:\n",
    "            print(f\"‚ùå TensorFlow Lite (.tflite) format: INCOMPLETE\")\n",
    "\n",
    "        # Check TFJS files\n",
    "        tfjs_model_json = os.path.join(config.TFJS_MODEL_DIR, \"model.json\")\n",
    "        if os.path.exists(tfjs_model_json):\n",
    "            bin_files = [f for f in os.listdir(config.TFJS_MODEL_DIR) if f.endswith(\".bin\")]\n",
    "            if bin_files:\n",
    "                print(f\"‚úÖ TensorFlow.js format: COMPLETE (model.json and {len(bin_files)} bin files exist)\")\n",
    "            else:\n",
    "                print(\"‚ùå TensorFlow.js format: INCOMPLETE (model.json exists but no bin files found)\")\n",
    "        else:\n",
    "            print(\"‚ùå TensorFlow.js format: INCOMPLETE (model.json not found)\")\n",
    "\n",
    "        # Final update to model.json\n",
    "        try:\n",
    "            if os.path.exists(config.MODEL_JSON_PATH):\n",
    "                with open(config.MODEL_JSON_PATH, \"r\") as f:\n",
    "                    model_info = json.load(f)\n",
    "            else:\n",
    "                model_info = {}\n",
    "\n",
    "            model_info[\"pipeline_completed\"] = True\n",
    "            model_info[\"completion_time\"] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            with open(config.MODEL_JSON_PATH, \"w\") as f:\n",
    "                json.dump(model_info, f, indent=4)\n",
    "\n",
    "            print(f\"\\nProcessing complete! Check {config.MODEL_JSON_PATH} for full execution details.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating final model.json: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error in main execution: {str(e)}\")\n",
    "        # Try to create model.json as emergency fallback\n",
    "        emergency_info = {\n",
    "            \"status\": \"emergency_fallback\",\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "        try:\n",
    "            # Ensure TFJS directory exists\n",
    "            os.makedirs(\"tfjs_model\", exist_ok=True)\n",
    "            # Create emergency model.json\n",
    "            with open(os.path.join(\"tfjs_model\", \"model.json\"), \"w\") as f:\n",
    "                json.dump(\n",
    "                    {\n",
    "                        \"format\": \"tfjs-layers-model\",\n",
    "                        \"generatedBy\": \"emergency-fallback\",\n",
    "                        \"error\": str(e),\n",
    "                        \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        \"weightsManifest\": [{\"paths\": [\"group1-shard1of1.bin\"], \"weights\": []}],\n",
    "                    },\n",
    "                    f,\n",
    "                    indent=2,\n",
    "                )\n",
    "\n",
    "            # Create a dummy bin file\n",
    "            with open(os.path.join(\"tfjs_model\", \"group1-shard1of1.bin\"), \"wb\") as f:\n",
    "                f.write(b\"\\x00\" * 1024)  # Write 1KB of zeros\n",
    "\n",
    "            print(\"Emergency model.json and bin file created in tfjs_model directory\")\n",
    "\n",
    "            # Also save to main model_info.json\n",
    "            with open(\"model_info.json\", \"w\") as f:\n",
    "                json.dump(emergency_info, f, indent=4)\n",
    "        except Exception as inner_e:\n",
    "            print(f\"Even emergency fallback failed: {str(inner_e)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
